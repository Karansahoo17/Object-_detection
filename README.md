# ğŸš€ YOLOv5 Object Detection with Streamlit

## ğŸ“Œ Overview
This repository provides an end-to-end pipeline for object detection using YOLOv5. It includes data preprocessing, model training, and a user-friendly Streamlit application for real-time image and video inference. 

## ğŸ“‚ Repository Structure
```
ğŸ“¦ YOLOv5-Streamlit-Detection
â”œâ”€â”€ ğŸ“ model/            # Contains training summary images (F1 curve, confusion matrix, etc.)
â”œâ”€â”€ ğŸ“ test_images/      # Test images and videos for inference
â”œâ”€â”€ ğŸ“„ app_pred.py       # Streamlit application for object detection
â”œâ”€â”€ ğŸ“„ data.yaml         # Dataset configuration file
â”œâ”€â”€ ğŸ“„ yolo_pred.ipynb   # Preprocessing and inference code
â”œâ”€â”€ ğŸ“„ yolo_train.ipynb  # Model training and weight saving
â”œâ”€â”€ ğŸ“ weights/          # Directory for trained model weights
```

## âš™ï¸ Installation
Ensure you have Python installed, then clone the repository and install dependencies:
```bash
pip install -r requirements.txt
```

## ğŸ¯ Training the Model
To train the YOLOv5 model:
1. Open `yolo_train.ipynb` in Jupyter Notebook or Google Colab.
2. Run the notebook cells to preprocess data, train the model, and save the trained weights.
3. The model weights will be saved in the `weights/` directory.

## ğŸ–¼ï¸ Running Inference
To test the model on new images and videos:
1. Open `yolo_pred.ipynb` and run the cells to preprocess test data and perform inference.
2. Test images and videos should be placed in the `test_images/` folder.

## ğŸŒ Streamlit Application
To run the Streamlit-based object detection app:
```bash
streamlit run app_pred.py
```
This will launch a web interface where you can upload images and videos for real-time object detection.

## ğŸ–¥ï¸ Screenshots
### ğŸ”¹ Streamlit App Interface:
![Streamlit App](screenshots/.png)

### ğŸ”¹ Object Detection on Image:
![Object Detection Image](screenshots/detection_image.png)

### ğŸ”¹ Object Detection on Video:
![Object Detection Video](screenshots/detection_video.png)

## ğŸ“Š Dataset Configuration
The dataset details are specified in `data.yaml`. This file includes:
- ğŸ”¢ Number of classes (`nc`)
- ğŸ·ï¸ Class names
- ğŸ“ Path to training and validation data

## ğŸ“ˆ Results & Model Performance
Training performance metrics such as:
âœ… F1-score
âœ… Precision
âœ… Recall
âœ… Confusion Matrix

Can be found in the `model/` directory. ğŸ“Š

## ğŸ¤ Contributing
Feel free to fork this repository, make improvements, and submit a pull request! ğŸš€

## ğŸ“œ License
This project is open-source and available under the MIT License.

